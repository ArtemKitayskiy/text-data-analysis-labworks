# Лабораторная работа №1. Бинарная классификация фактографических данных

## Цель работы

Получить практические навыки решения задачи бинарной классификации данных в среде Jupyter Notebook. 
Научиться загружать данные, обучать классификаторы и проводить классификацию. Научиться оценивать точность полученных моделей.

## Задание

1.  В среде Jupyter Notebook создать новый ноутбук (Notebook) 
2.	Импортировать необходимые для работы библиотеки и модули
3.	Загрузить данные в соответствие с вариантом 
4.	Вывести первые 15 элементов выборки (координаты точек и метки класса)
5.	Отобразить на графике сгенерированную выборку. Объекты разных классов должны иметь разные цвета.
6.	Разбить данные на обучающую (`train`) и тестовую (`test`) выборки в пропорции 75% - 25% соответственно.
7.	Отобразить на графике обучающую и тестовую выборки. Объекты разных классов должны иметь разные цвета.
8.	Реализовать модели классификаторов, обучить их на обучающем множестве. Применить модели на тестовой выборке, вывести результаты классификации:

	*	Истинные и предсказанные метки классов
	*	Матрицу ошибок (`confusion matrix`)
	*	Значения полноты, точности, f1-меры и аккуратности
	*	Значение площади под кривой ошибок (`AUC ROC`)
	*	Отобразить на графике область принятия решений по каждому классу

В качестве методов классификации использовать: 

	* Метод к-ближайших соседей (`n_neighbors` = {1, 3, 9})
	* Наивный байесовский метод
	* Случайный лес (`n_estimators` = {5, 15, 50})

9.	По результатам п.8 занести в отчет таблицу с результатами классификации всеми методами.
10. Изучить, как изменится качество классификации в случае другого разбиения выборки на обучающую и тестовую. Для этого повторить пункты 6, передав в параметр `random_state` новое значение, и пункты 8-9 дважды. 
11. По результатам трех экспериментов составить итоговую таблицу о качестве классификаци каждым методом, включив в нее значения полноты, точности, f1-меры, аккуратности и площади под кривой ошибок. 
Сделать выводы о наиболее подходящем методе классификации ваших данных

## Варианты заданий

Объем выборки для всех вариантов – `n_samples = 1000` объектов.
| Вариант     | 1     | 2     | 3     | 4     | 5     | 6     | 7     | 8     |
| :---        | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
| Вид классов | blobs | blobs | blobs | blobs | moons | moons | moons | moons |
| random_state| 34    | 28    | 41    | 23    | 41    | 23    | 77    | 15    |
| cluster_std | 1.5   | 4.5   | 3     | 5     | -     | -     | -     | -     |
| noise       | -     | -     | -     | -     | 0.25  | 0.3   | 0.25  | 0.2   |
| centers     | 2     | 2     | 2     | 2     | -     | -     | -     | -     |


| Вариант     | 9     | 10    | 11    | 12    | 
| :---        | :---: | :---: | :---: | :---: | 
| Вид классов | classification | classification | classification | classification |
| random_state| 78    | 58    | 15    | 30    | 
| class_sep   | 0.45  | 0.7   | 0.6   | 1.0   |

Для всех вариантов, использующих для генерации `make_classification`, дополнительные параметры: `n_features=2`,  `n_redundant=0`,  `n_informative=1`, `n_clusters_per_class=1`,

## Контрольные вопросы

1.	Постановка задачи классификации данных. Что такое бинарная классификация?
2.	Общий алгоритм решения задачи классификации данных.
3.	Чем отличаются обучающая и тестовая выборки? Какие существуют способы формирования обучающей и тестовой выборок?
4.	Как рассчитываются значения полноты и точности классификации?
5.	Как рассчитывается значение площади под кривой ошибок?
6.	Что показывает и как рассчитывается матрица ошибок?
7.	Алгоритм и особенности метода к-ближайших соседей.
8.	Алгоритм и особенности метода случайного леса.


