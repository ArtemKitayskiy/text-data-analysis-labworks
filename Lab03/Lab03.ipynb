{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лабораторная работа №3. Классификация текстовых данных\n",
    "\n",
    "**Выполнил:** Китайский А.С.\n",
    "\n",
    "**Проверил:** Мохов А.С."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Загрузка данных"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Вариант | Метод   | Word embedding         |\n",
    "|---------|---------|------------------------|\n",
    "| 8       | SVM, DT | glove-wiki-gigaword-50 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['comp.sys.mac.hardware', 'soc.religion.christian', 'talk.religion.misc'] \n",
    "remove = ('headers', 'footers', 'quotes')\n",
    "twenty_train = fetch_20newsgroups(subset='train', shuffle=True, random_state=42, categories=categories, remove=remove)\n",
    "twenty_test = fetch_20newsgroups(subset='test', shuffle=True, random_state=42, categories=categories, remove=remove)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Используя GridSearchCV произведем предварительную обработку данных и настройку методов классификации в соответствие с заданием, выведем оптимальные значения параметров и результаты классификации модели (полнота, точность, f1-мера и аккуратности) с данными параметрами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "def print_score(prediction, y_test):\n",
    "    '''Расчет показателей качества'''\n",
    "    precision = round(precision_score(prediction, y_test, average='weighted'), 3)\n",
    "    print ('Precision score: ', precision)\n",
    "    recall = round(recall_score(prediction, y_test, average='weighted'), 3)\n",
    "    print ('Recall score: ', recall)\n",
    "    f1 = round(f1_score(prediction, y_test, average='weighted'), 3)\n",
    "    print ('F1-score: ', f1)\n",
    "    accuracy = round(accuracy_score(prediction, y_test), 3)\n",
    "    print ('Accuracy score: ', accuracy)\n",
    "\n",
    "    return [precision, recall, f1, accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['precision', 'recall', 'f1-score', 'accuracy']\n",
    "df = pd.DataFrame(columns=columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод опорных векторов (SVM):\n",
    "\n",
    "- функция потерь (параметр kernel: ‘linear’, ‘rbf’),\n",
    "- регуляризация (параметр C: {0.1, 1, 5})."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('vect', CountVectorizer()),\n",
       "                                       ('tfidf', TfidfTransformer()),\n",
       "                                       ('clf', SVC())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'clf__C': (0.1, 1, 5),\n",
       "                         'clf__kernel': ('linear', 'rbf'),\n",
       "                         'tfidf__use_idf': (True, False),\n",
       "                         'vect__max_features': [100, 500, 1000, 5000, 10000],\n",
       "                         'vect__stop_words': ('english', None)},\n",
       "             verbose=10)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'vect__max_features': [100, 500, 1000, 5000, 10000],\n",
    "              'vect__stop_words': ('english', None),\n",
    "              'tfidf__use_idf': (True, False),              \n",
    "              'clf__kernel': ('linear', 'rbf'),\n",
    "              'clf__C': (0.1, 1, 5)} \n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('clf', SVC()),])   \n",
    "\n",
    "gs_clf = GridSearchCV(text_clf, parameters, cv=3, n_jobs=-1, verbose=10)\n",
    "gs_clf.fit(twenty_train.data, twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__C': 1,\n",
       " 'clf__kernel': 'linear',\n",
       " 'tfidf__use_idf': True,\n",
       " 'vect__max_features': 10000,\n",
       " 'vect__stop_words': 'english'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score:  0.82\n",
      "Recall score:  0.8\n",
      "F1-score:  0.806\n",
      "Accuracy score:  0.8\n"
     ]
    }
   ],
   "source": [
    "pred = gs_clf.predict(twenty_test.data)\n",
    "df.loc['SVM_Pipeline'] = print_score(pred, twenty_test.target)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дерево решений (DT):\n",
    "\n",
    "- критерий (параметр criterion: ‘gini’, ‘entropy’),\n",
    "- глубина дерева (параметр max_depth: {5, 15, 50, 100})."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 160 candidates, totalling 480 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('vect', CountVectorizer()),\n",
       "                                       ('tfidf', TfidfTransformer()),\n",
       "                                       ('clf', DecisionTreeClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'clf__criterion': ('gini', 'entropy'),\n",
       "                         'clf__max_depth': (5, 15, 50, 100),\n",
       "                         'tfidf__use_idf': (True, False),\n",
       "                         'vect__max_features': (100, 500, 1000, 5000, 10000),\n",
       "                         'vect__stop_words': ('english', None)},\n",
       "             verbose=10)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'vect__max_features': (100, 500, 1000, 5000, 10000),\n",
    "              'vect__stop_words': ('english', None),\n",
    "              'tfidf__use_idf': (True, False),              \n",
    "              'clf__criterion': ('gini', 'entropy'),\n",
    "              'clf__max_depth': (5, 15, 50, 100)} \n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('clf', DecisionTreeClassifier()),])   \n",
    "\n",
    "gs_clf = GridSearchCV(text_clf, parameters, cv=3, n_jobs=-1, verbose=10)\n",
    "gs_clf.fit(twenty_train.data, twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__criterion': 'gini',\n",
       " 'clf__max_depth': 100,\n",
       " 'tfidf__use_idf': False,\n",
       " 'vect__max_features': 5000,\n",
       " 'vect__stop_words': 'english'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score:  0.625\n",
      "Recall score:  0.64\n",
      "F1-score:  0.627\n",
      "Accuracy score:  0.64\n"
     ]
    }
   ],
   "source": [
    "pred = gs_clf.predict(twenty_test.data)\n",
    "df.loc['DT_Pipeline'] = print_score(pred, twenty_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVM_Pipeline</th>\n",
       "      <td>0.820</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT_Pipeline</th>\n",
       "      <td>0.625</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision  recall  f1-score  accuracy\n",
       "SVM_Pipeline      0.820    0.80     0.806      0.80\n",
       "DT_Pipeline       0.625    0.64     0.627      0.64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Переведем выборку к векторному представлению word embedding согласно варианту."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis']\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader\n",
    "from gensim.models import KeyedVectors\n",
    "print(list(gensim.downloader.info()['models'].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_model = KeyedVectors.load_word2vec_format('glove-wiki-gigaword-50.txt', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.37854  ,  1.8233   , -1.2648   , -0.1043   ,  0.35829  ,\n",
       "        0.60029  , -0.17538  ,  0.83767  , -0.056798 , -0.75795  ,\n",
       "        0.22681  ,  0.98587  ,  0.60587  , -0.31419  ,  0.28877  ,\n",
       "        0.56013  , -0.77456  ,  0.071421 , -0.5741   ,  0.21342  ,\n",
       "        0.57674  ,  0.3868   , -0.12574  ,  0.28012  ,  0.28135  ,\n",
       "       -1.8053   , -1.0421   , -0.19255  , -0.55375  , -0.054526 ,\n",
       "        1.5574   ,  0.39296  , -0.2475   ,  0.34251  ,  0.45365  ,\n",
       "        0.16237  ,  0.52464  , -0.070272 , -0.83744  , -1.0326   ,\n",
       "        0.45946  ,  0.25302  , -0.17837  , -0.73398  , -0.20025  ,\n",
       "        0.2347   , -0.56095  , -2.2839   ,  0.0092753, -0.60284  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_model['queen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('princess', 0.8515166640281677),\n",
       " ('lady', 0.8050609230995178),\n",
       " ('elizabeth', 0.7873042225837708),\n",
       " ('king', 0.7839043736457825),\n",
       " ('prince', 0.7821860909461975),\n",
       " ('coronation', 0.769277811050415),\n",
       " ('consort', 0.7626097202301025),\n",
       " ('royal', 0.7442865371704102),\n",
       " ('crown', 0.7382649779319763),\n",
       " ('victoria', 0.7285771369934082)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_model.most_similar('queen') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7839043"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_model.similarity('queen', 'king')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.8523604273796082)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_model.most_similar(positive=['king', 'woman'], negative=['man'], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text_data, model=glove_model, embedding_size=50):\n",
    "    \n",
    "    vect = CountVectorizer(stop_words='english')\n",
    "    data = vect.fit_transform(text_data)\n",
    "    feature_names = vect.get_feature_names_out() \n",
    "    \n",
    "    doc_vectors = [] # список векторов\n",
    "    for doc in range(data.toarray().shape[0]):\n",
    "\n",
    "        one_doc = np.zeros(embedding_size) #вектор одного документа\n",
    "        cnt = 0 # счетчик слов в документе\n",
    "\n",
    "        # итерируемся по каждому документу и проверяем присутствие слов в словаре\n",
    "        for word in feature_names[(data[doc,:] > 0).toarray()[0]]:\n",
    "\n",
    "            if word in glove_model.key_to_index.keys():\n",
    "                one_doc += np.array(model[word]) # суммируем вектора каждого известного слова\n",
    "                cnt += 1\n",
    "        if cnt:\n",
    "            one_doc = one_doc / cnt # находим средний вектор для всех слов\n",
    "        doc_vectors.append(one_doc)\n",
    "    return doc_vectors\n",
    "\n",
    "doc_vectors_train = np.array(get_embedding(twenty_train.data))\n",
    "doc_vectors_test = np.array(get_embedding(twenty_test.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1554, 50)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_vectors_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01000642, -0.84533757,  0.60926716,  0.48792141,  0.10409343,\n",
       "       -0.07573429,  0.30370214,  0.06054314,  0.15884714,  0.03314629,\n",
       "        0.54265715,  0.16442856,  0.115942  ,  0.23572257, -0.05171   ,\n",
       "        0.67733457, -0.22834142,  0.03366345,  0.32656929, -0.54170299,\n",
       "        0.42424572, -0.84615285,  0.29271187,  0.29938671, -0.20356429,\n",
       "       -0.07915413, -0.16294357, -0.04242514, -0.08724386, -0.08077858,\n",
       "        0.85820499, -0.29196881,  0.42105371,  0.57581516,  0.32741285,\n",
       "        0.26701228,  0.30354285,  0.34064314,  0.34719   ,  0.36802387,\n",
       "        0.24394104,  0.38733857, -0.35902187,  0.27397771,  0.26723285,\n",
       "        0.32777799, -0.06042128, -0.08401066,  0.12260586, -0.54703   ])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_vectors_train[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Проведем обучение и настройку тех же алгоритмов классификации и с теми же параметрами, что и в п.2, но на векторизованной выборке"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод опорных векторов (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(), n_jobs=-1,\n",
       "             param_grid={'C': (0.1, 1, 5), 'kernel': ('linear', 'rbf')})"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'kernel': ('linear', 'rbf'),\n",
    "              'C': (0.1, 1, 5)} \n",
    "\n",
    "gs_clf = GridSearchCV(SVC(), parameters, cv=5, n_jobs=-1)\n",
    "gs_clf.fit(doc_vectors_train, twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 5, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score:  0.847\n",
      "Recall score:  0.791\n",
      "F1-score:  0.809\n",
      "Accuracy score:  0.791\n"
     ]
    }
   ],
   "source": [
    "pred = gs_clf.predict(doc_vectors_test)\n",
    "df.loc['SVM_Glove'] = print_score(pred, twenty_test.target)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дерево решений (DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(), n_jobs=-1,\n",
       "             param_grid={'criterion': ('gini', 'entropy'),\n",
       "                         'max_depth': (5, 15, 50, 100)})"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'criterion': ('gini', 'entropy'),\n",
    "              'max_depth': (5, 15, 50, 100)} \n",
    "\n",
    "gs_clf = GridSearchCV(DecisionTreeClassifier(), parameters, cv=5, n_jobs=-1)\n",
    "gs_clf.fit(doc_vectors_train, twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy', 'max_depth': 5}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score:  0.776\n",
      "Recall score:  0.717\n",
      "F1-score:  0.739\n",
      "Accuracy score:  0.717\n"
     ]
    }
   ],
   "source": [
    "pred = gs_clf.predict(doc_vectors_test)\n",
    "df.loc['DT_Glove'] = print_score(pred, twenty_test.target)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Оформим сравнительную таблицу с результатами классификации различными методами с разными настройками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVM_Pipeline</th>\n",
       "      <td>0.820</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT_Pipeline</th>\n",
       "      <td>0.625</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM_Glove</th>\n",
       "      <td>0.847</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.809</td>\n",
       "      <td>0.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT_Glove</th>\n",
       "      <td>0.776</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision  recall  f1-score  accuracy\n",
       "SVM_Pipeline      0.820   0.800     0.806     0.800\n",
       "DT_Pipeline       0.625   0.640     0.627     0.640\n",
       "SVM_Glove         0.847   0.791     0.809     0.791\n",
       "DT_Glove          0.776   0.717     0.739     0.717"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:**   \n",
    "Из рассматриваемых методов наиболее подходящим для применения к данной задачи оказался метод опорных векторов с параметрами C=1 и kernal='linear'. Векторизация осуществлялась с использованием tf-idf, размерность признакого пространства составила 10000.  \n",
    "В случае метода опорных векторов использование предобученной модели не дало прибавки к качеству, тогда как для дерева решений этот подход позволил улучшить score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
