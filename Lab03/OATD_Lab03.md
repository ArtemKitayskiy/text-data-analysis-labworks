# Лабораторная работа №3. Классификация текстовых данных

## Цель работы

Получить практические навыки решения задачи классификации текстовых данных в среде Jupiter Notebook. 
Научиться проводить предварительную обработку текстовых данных, настраивать параметры методов классификации и обучать модели, оценивать точность полученных моделей

## Задание

1. Загрузить выборки по варианту из лабораторной работы №2. Стемминг проводить не нужно.
2. Используя GridSearchCV произвести предварительную обработку данных и настройку методов классификации в соответствие с заданием, 
вывести оптимальные значения параметров и результаты классификации модели (полнота, точность, f1-мера и аккуратности) с данными параметрами. 
3. Перевести выборку к векторному представлению word embedding согласно варианту.
4. Провести обучение и настройку тех же алгоритмов классификации и с теми же параметрами, что и в п.2, но на векторизованной выборке
5. По каждому пункту работы занести в отчет программный код и результат вывода.
6. Оформить сравнительную таблицу с результатами классификации различными методами с разными настройками. 
Сделать выводы о наиболее подходящем методе классификации ваших данных с указанием параметров метода и описанием предварительной обработки данных.



## Варианты заданий

| Вариант | Метод    | Word embedding |
| :---    | :---     | :---           | 
| 1       | KNN, SVM | glove-wiki-gigaword-100 |
| 2       | RF, MNB  | glove-wiki-gigaword-50
| 3       | KNN, DT  | glove-wiki-gigaword-200 |
| 4       | RF, KNN  | glove-wiki-gigaword-25 |
| 5       | LR, MNB  | word2vec-google-news-300 |
| 6       | DT, LR   | glove-wiki-gigaword-200 |
| 7       | RF, SVM  | glove-wiki-gigaword-100 |
| 8       | SVM, DT  | glove-wiki-gigaword-50 |
| 9       | RF, SVM  | glove-wiki-gigaword-200 |
| 10      | MNB, SVM | glove-wiki-gigaword-25 |
| 11      | MNB, DT  | word2vec-google-news-300 |
| 12      | RF, LR   | glove-wiki-gigaword-200 | 

## Параметры, которые необходимо настроить

Помимо параметров предварительной обработки, таких как: взвешивание, отсечение стоп-слов,
количество информативных терминов, для каждого метода классификации необходимо настроить следующие параметры:
**К-ближайших соседей (KNN):**

* количество ближайших соседей, 
* метрика (евклидова, косинусная) 


**Дерево решений (DT):**

* критерий (параметр criterion: ‘gini’, ‘entropy’), 
* глубина дерева (параметр max_depth: {5, 15, 50, 100}).

**Случайный лес (RF):**

* количество деревьев решений, 
* критерий (параметр criterion: ‘gini’, ‘entropy’),
* глубина дерева (5, 15, 50, 100).

**Логистическая регрессия (LR):**

* метод нахождения экстремума (параметр solver: ‘newton-cg’, ‘lbfgs’, ‘sag’, ‘liblinear’), 
* регуляризация (параметр penalty: ‘L1’, ‘L2’)
Обратить внимание, что разные виды регуляризации работают с разными методами нахождения экстремума.

**Метод опорных векторов (SVM):**
* функция потерь (параметр kernel: ‘linear’, ‘rbf’), 
* регуляризация (параметр C: {0.1, 1, 5})
Обратить внимание, что разные виды регуляризации работают с разными функциями потерь

**Мультиномиальный Наивный Байесовский метод (MNB)**
* параметр сглаживания α (параметр alpha: {0.1, 1, 2})

## Контрольные вопросы

1. Алгоритм и особенности метода опорных векторов.
2. Алгоритм и особенности метода логистической регрессии.
3. Алгоритм и особенности метода деревьев решений.
4. Что такое регуляризация?
5. Что такое метрика расстояния? Какие метрики вам известны?



